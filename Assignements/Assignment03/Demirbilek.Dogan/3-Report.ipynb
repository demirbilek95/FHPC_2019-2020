{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "## The Mandelbrot set \n",
    "\n",
    "## Openmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all, for the given problem serial code is written. After that this code is openmpized in a straightforward way. In this implementation of openmp, it is observed (by measuring minimum, maximum and average thread times) that there is work unbalance since some points diverge rapidly as expected. Therefore different ways were searched to get balanced parallel algorithm.\n",
    "\n",
    "First idea is to use schedule directives with different scheduling types and chunk-sizes to make threads have same amount of workload. Although this implementation is better than straightforward one, it doesn't scale. Second idea which balanced the workload is using collapse directives with schedule directive. By using collapse directive nested for loops collapsed into one large iteration. This implementation gives balanced (minimum, maximum and average threads times very close to each other) and scaling parallel algorithm.\n",
    "\n",
    "Below plots shows the performance (strong and weak scaling) of algorithm (with collapse and schedule directives) with comparison to straightforward implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since elapsed time and wall time about same, for scaling tests only one of it used. \n",
    "\n",
    "For strong scaling test below parameters are used:\n",
    "\n",
    "$nx=1024$, $ny=1024$, $xL=-2$, $yL=-2$, $xR=2$, $yR=2$, $Imax=40000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Speed Up / # Threads |  | 1 | 2     | 4     | 8     | 12     | 16     | 20     | \n",
    "|-----------------------------------|--|---|-------|-------|-------|--------|--------|--------| \n",
    "| Balanced                    |  | 1 | 1.965 | 3.822 | 7.206  | 10.180  | 13.570  | 16.902  | \n",
    "| Straight                   |  | 1 | 1.948| 1.947 | 2.345 | 3.114 | 3.841 | 4.595 | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Strong_Scaling](mandel_strong_scaling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below table you can find the comparison between straightforward and balanced version in terms of average, minimum and maximum thread times (just for 4 threads as an example but this situaiton valid for different number of threads)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Average, Minimum and Maximum thread run times (4 threads) |                 |          | \n",
    "|-----------------------------------------------------------|-----------------|----------| \n",
    "|                                                           | Straightforward | Balanced | \n",
    "| Average                                                   | 21.5            | 21.7     | \n",
    "| Min                                                       | 0.16            | 21.7     | \n",
    "| Max                                                       | 43.09           | 21.7     | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that straightforward implementation doesn't scale and unbalanced. However with the directives schedule and dynamic program is balanced and scales good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weak scaling test below parameters are used:\n",
    "\n",
    "$nx=1024$, $ny=1024$, $xL=-2$, $yL=-2$, $xR=2$, $yR=2$, ${procs} \\times 10000$ where $procs=thread number$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Elapsed Time (Weak Scaling) / # Threads |  | 2     | 4     | 8     | 12    | 16   | 20    | \n",
    "|-----------------------------------------|--|-------|-------|-------|-------|------|-------| \n",
    "| Balanced                                  |  | 21.48 | 21.81 | 22.98 | 24.25 | 24.26 | 24.26 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Weak](mandel_weak_scaling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to logic of weak scalability when we increase the number of threads with the same amount of work per thread, runtimes supposed to be same. However for this example there are small differences. There might be some room for optimization of parallelization part. But after 12 threads run time became more or less constant. This happens most probably because of Ullyses architecture (two socket - 10 cores each socket)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MPI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strong Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing MPI process is different than openmp paradigm. Several methods considered by me, for example dividing matrix (image matrix) row by row and sending to available core, or dividing matrix to submatrix and assigning to cores, these methods weren't implemented because I thought that sending row by row may spawn more overhead due to the communication time, submatrix regions can be unbalanced naturally (points in some submatrices may diverge rapidly with high probably on the other hand some of them may not).\n",
    "    \n",
    "The algorithm which is used for the solution of problem, each core takes part of matrix index by index starting from their rank up to end of matrix with the increment of size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image below represents the work sharing between cores. 4x10 matrix is divided for 4 cores. By implementing this, master core didn't create big matrix and assign the work for each core. Instead of this, amount of work (called N), coordinates (xL, yL, xR, yR), pixels and iteration (nx, ny, Imax) are broadcasted. Indices of big matrix and mandelbrot results are gathered from each core.\n",
    "    \n",
    "![Algorithm](algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For strong scaling test below parameters are used:\n",
    "\n",
    "$nx=1024$, $ny=1024$, $xL=-2$, $yL=-2$, $xR=2$, $yR=2$, $Imax =3000$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Speed Up/ # Cores | 1 | 2    | 4    | 8    | 16    | 20    | \n",
    "|-------------------|---|------|------|------|-------|-------| \n",
    "| MPI               | 1 | 1.95 | 3.85 | 6.91 | 12.43 | 14.69 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Strong](mpi_strong_scaling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to strong scaling results algorithm scales. However after 5 cores most probably because of communication overhead (2 sockets) it doesn't scale as good as in 1 socket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the balance of workload, each cores run time printed. It is observed that work load is balanced among the cores. Below table shows the runtimes for 8 cores as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Core ID  | 0     | 1     | 2     | 3     | 4     | 5     | 6     | 7     | \n",
    "|----------|-------|-------|-------|-------|-------|-------|-------|-------| \n",
    "| Run Time | 38.83 | 38.82 | 38.82 | 38.82 | 38.82 | 38.82 | 38.82 | 38.87 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weak Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For weak scaling test below parameters are used:\n",
    "\n",
    "$nx=1024$, $ny=1024$, $xL=-2$, $yL=-2$, $xR=2$, $yR=2$, ${procs} \\times 500$ where $procs=core number$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Elapsed Time (Weak Scaling) / # Core |  | 2     | 4     | 8     | 12    | 16   | 20    | \n",
    "|-----------------------------------------|--|-------|-------|-------|-------|------|-------| \n",
    "| Run Time                                |  | 54.41 | 51.24 | 52.45 | 53.90 | 54.47 | 63.52 | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Weak](mpi_weak_scaling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weak scaling test of mpi code is done several times but every time different results are observed, most probably taken node effected the test. Hence last trial will be evaluated. \n",
    "\n",
    "Up to 16 cores, run times are more or less same with small differences. However for 20 cores it is bit more than other run times. This may happen because when iteration increase, the data which is transferred increase also, this situation may cause a slow communication between cores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPI IO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mpi io part, plane coordinates (as doubles), pixels and max iteration (as integers) and lastly calculated matrix is written to byte file. To control the file there is another python script with mpi io, which shows the written file and save the image of mandelbrotset.\n",
    "    Plane coordinates and pixels and max iteration is written by using collective opperation on the other hand matrix is written by creating contigious block."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
