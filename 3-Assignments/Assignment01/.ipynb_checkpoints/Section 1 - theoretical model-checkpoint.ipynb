{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- devise a performance model for a simple parallel algorithm: sum of N numbers\n",
    "\n",
    "  - Serial Algorithm : n-1 operations \n",
    "\n",
    "     $T_{serial}= N*T_{comp}$  where\n",
    "    $T_{comp}$ *is time to compute a floating point operation*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - Parallel Algorithm : master-slave\t\n",
    "\n",
    "    - read N and distribute N to P-1  slaves ===>  $T_{read} + (P-1) * T_{comm}$ where\n",
    "      $T_{comm}$ is *time  each processor takes to communicate one message, i.e. latency..*\n",
    "      $T_{read}$   = *time  master takes to read* \n",
    "\n",
    "    - N/P sum over each processors (including master)  ===> $T_{comp}/N$\n",
    "\n",
    "    - Slaves send partial sum  ===>   $(P-1) * T_{comm}$\n",
    "\n",
    "    - Master performs  one final sum ===>  $(P-1) * T_{comp}$\n",
    "\n",
    "      the final model:    $T_p=   T_{comp}* (P -1 + n/P)  + T_{read} + 2(P-1) * T_{comm}  $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* N: numbers to be sum\n",
    "* T_comp: time to compute a floating point operation\n",
    "* T_read: time master takes to read\n",
    "* P: number of processors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "#Assumptions\n",
    "\n",
    "T_comp = 2e-09\n",
    "T_read = 1e-04\n",
    "T_comm = 1e-06\n",
    "P = np.arange(1,1000+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compute scalability curves for such algorithm and make some plots\n",
    "- Play with some value of N and plot against P  (with P ranging from 1 to 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Section_1 Scalability](logo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='./codes/section1_scalability.py' target='_blank'>./codes/section1_scalability.py</a><br>"
      ],
      "text/plain": [
       "/media/john/Yerel Disk/Doğan/1-Akademik/Yüksek Lisans/1- Dersler/High Performance Computing/FHPC_2019-2020/D04/Demirbilek.Dogan/codes/section1_scalability.py"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.FileLink(path=\"./codes/section1_scalability.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Section_1 Scalability](section1_scalability.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  - For which values of N do you see the algorithm scaling ? \n",
    "\n",
    "  - For which values of P does the algorithm produce the best results ? \n",
    "  \n",
    "For P = [1,1000], when N gets larger, algorithm tends to scale better. \n",
    "\n",
    "Best scaling P values are highly dependent on N, when N is smaller best scaling value of P is small as well. For instances: For N = $10^9$ best scaling value of P is 1000, for N = $10^8$ best scaling value of P is 316, for N $10^7$ best scaling value of P is 100 and for N = $10^6$ best scaling value of P 32. It means that if N is large enough more processors give better results up to specific point. For smaller N, best P tends to be smaller as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Section_1 Scalability](logo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='./codes/section1_efficiency.py' target='_blank'>./codes/section1_efficiency.py</a><br>"
      ],
      "text/plain": [
       "/media/john/Yerel Disk/Doğan/1-Akademik/Yüksek Lisans/1- Dersler/High Performance Computing/FHPC_2019-2020/D04/Demirbilek.Dogan/codes/section1_efficiency.py"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.FileLink(path=\"./codes/section1_efficiency.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Section_1 Scalability](section1_efficiency.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As it can be seen from the plot, for the changing values of N, best P values have the most efficient points as same as previous plot. For N = $10^6$ algorithm is most efficient at P = 32, after that point efficiency decrease. For N = $10^9$ , it has more way to best efficient point. However for the range of P = [1,1000], most efficient point is P = 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can you try to modify the algorithm sketched above to increase its scalability ?\n",
    "    * Reducing communication time should increase the scalability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Section_1 Scalability](logo.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='./codes/section1_better_comm.py' target='_blank'>./codes/section1_better_comm.py</a><br>"
      ],
      "text/plain": [
       "/media/john/Yerel Disk/Doğan/1-Akademik/Yüksek Lisans/1- Dersler/High Performance Computing/FHPC_2019-2020/D04/Demirbilek.Dogan/codes/section1_better_comm.py"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display.FileLink(path=\"./codes/section1_better_comm.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Section_1 Scalability](section1_reduce_comm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Indeed, when I reduce the communication time (for example using collective operations) algorithm tends to scale better. For example, N = $10^6$ best speed up value when P is 100 and for N = $10^7$ best speed up value when P is 315 and so on."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
